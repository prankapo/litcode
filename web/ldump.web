\subsection{ldump.py}

Tangling a chunk involves recursive expansion of all the references that are there in the chunk. The
indentation of a reference must be appended while printing all the lines of the chunk it refers to. We also
need to add some markers which tell a programmer from where a piece of code lies in the WEB files. We also
need to ensure that proper whitespace conversion is done --- this is especially useful in the case of \tt
Makefile \rm which accepts only tabs as valid indentation characters.\\

Most of the traditional literate programming tools tangle a chunk by going through a file, making a dictionary
of chunks and then expanding the required chunk recursively. What would happen if we need to tangle 2 chunks
from the same file? Some computational power will be expended in setting up the dictionary twice. To prevent
this `waste of computational power' (although in the 21st century, hardly anyone cares about it for such
simple text processing job), I have written \tt ldump.py \rm. It will make a dicitionary of chunks which are
present in the files which have been supplied to it as command line arguments. Then this dictionary will be
printed and can be saved in a JSON file using the clobber operator, \tt > \rm. This JSON will be used by \tt
ltangle \rm when tangling a piece of code. \\

\textbf{NOTE:} If a chunk is defined in multiple files and have no relation to each other, give them different
names. This will prevent \tt ltangle \rm and \tt lweave \rm from considering them as related to each other.\\

We begin with the shebang line specifying the path of the python3 and import \tt os\rm, \tt sys\rm, \tt
json \rm and \tt re \rm modules.

<<ldump.py>>=
import os
import sys
import re
import json

@

A pseudocode for \tt ldump.py \rm is presented in Algorithm~\ref{algo:ldump-working}:

\begin{algorithm}

Check if command line args have been supplied. \linebreak
If yes: then start reading each file line by line \linebreak
If not: then throw an error\\

Go through the string and look lines satisfying the regex: \linebreak
    \verb|(?<=^<<).+?(?=>>=\s*$)|\\

Check if the chunk exists or not. If it is not their in the dictionary, then enter it. Else, we will append
the lines in this chunk to the already existing lines in the dictionary.\\

Add some metadata about the position of chunk boundaries in the web files.\\

JSONify the dictionary and print it. Writing to the file will be taken care of by \tt > \rm operator.

\caption{Pseudocode for \texttt{ldump.py}}
\label{algo:ldump-working}
\end{algorithm}

We will be having a function \tt dumper \rm which will take in a list of files, read them line by line and
create a dictionary of chunks, \tt chunkDict \rm. This dictionary will then be converted into a pretty-printed
JSON string using \tt dumps \rm method in \tt json \rm package.

<<ldump.py>>=
def dumper(file_list):
    chunkDict = dict()
    for f in file_list:
        <<Fill chunkDict>>
    chunkJSON = json.dumps(chunkDict, indent = 4)
    return chunkJSON

@

Our entry point into the program will be \tt main() \rm which will see if the files have been supplied as
command line args or not. If they exist, we will send this list to the \tt dumper \rm. The JSON string that it
gets from the \tt dumper \rm will be printed on the screen.

<<ldump.py>>=
def main():
    if len(sys.argv) <= 1:
        print('No files provided')
        exit(1)
    file_list = sys.argv[1:]
    json_str = dumper(file_list)
    print(json_str)

@

We now have to write some code which will write \tt chunkDict \rm. When reading a file, we need to keep track
of the following:

\begin{enumerate}
    \item Line number of the current line being read.
    \item Are we in a chunk or not?
        \begin{itemize}
            \item If not, then does this line defines a chunk? Is it really new or an old one?
            \item If yes, then does this line refers to another chunk? Is there a \verb|@| in this line?
            (which marks the end of a chunk's definition)
        \end{itemize}
\end{enumerate}

We keep track of these conditions with the help of \verb|line_count|, \tt inChunk\rm, \tt
encounteredReference\rm, and \tt encounteredStopChar\rm variables.

<<Fill chunkDict>>=
line_count = 0
inChunk = False
encounteredReference = False
encounteredStopChar = False

@

We will read all the lines of a file and store them in a list (\tt lines \rm) in one shot using \tt readlines
\rm method. \tt chunkLines \rm will store the lines of a chunk as and when we encounter. It will be off-loaded
into \tt chunkDict \rm.

<<Fill chunkDict>>=
with open(f, 'r') as fp:
    lines = fp.readlines()
chunkLines = []

@

Using a \tt for \rm loop I am now going to iterate over \tt lines \rm. The first step in each iteration would
be to increment \verb|line_count|.

<<Fill chunkDict>>=
for line in lines:
    line_count += 1
    <<Fill chunkDict: Not in a chunk>>
    <<Fill chunkDict: In a chunk>>
@

There will be two conditions. Either I will be in a chunk or I won't. If I am not in a chunk, \tt inChunk \rm
is set to \tt False \rm, and I have to check whether the current line is the beginning of a chunk definition
or not.

<<Fill chunkDict: Not in a chunk>>=
if not inChunk:
    chunkname = re.findall(r'(?<=^<<).+?(?=>>=\s*$)', line.strip())
    if chunkname:
        inChunk = True

@

I now need to check whether the chunk has been previously defined or not. This can be easily done with the use
of \tt in \rm operator. Remember that \tt re.findall() \rm returns a list, so I need to set \tt chunkname \rm
to the first element of the list that has been returned by \tt findall()\rm.

<<Fill chunkDict: Not in a chunk>>=
        chunkname = chunkname[0]
        if chunkname not in chunkDict:
            chunkDict[chunkname] = []
            chunkLines = []
            chunkLines.append(f'@->{chunkname}: Starts at line {line_count} in {f}\n')
        else:
            chunkLines = chunkDict[chunkname]
            chunkLines.append(f'@->{chunkname}: Extended at line {line_count} in {f}\n')

@

Note how I am introducing metadata beginning with \verb|@->| at the beginning of the chunk. \\

I have to now deal with the condition in which I am inside a chunk. When inside a chunk, I need to check
whether the current line contains a reference or a stop-character (signaling end of the chunk), and
accordingly insert metadata at chunk boundaries.

<<Fill chunkDict: In a chunk>>=
else:
    encounteredStopChar = (line.strip() == '@')
    if encounteredStopChar:
        chunkLines.append(f'@->{chunkname}: Ends at {line_count} in {f}\n')
        chunkDict[chunkname] = chunkLines
        inChunk = False
        continue
    else:
        encounteredReference = re.findall(r'(?<=^<<).+?(?=>>\s*$)', line.strip())
        if encounteredReference:
            chunkLines.append(f'@->{chunkname}: Reference at line {line_count} in {f}\n')
            chunkLines.append(line)
            chunkLines.append(f'@->{chunkname}: Continues from line {line_count + 1} in {f}\n')
        else:
            chunkLines.append(line)
@
